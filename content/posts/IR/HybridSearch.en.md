---
title: "HybridSearch"
subtitle: "Summery of Pinecone paper and article"
date: 2023-03-06T17:46:41+08:00
draft: true
toc: true
categories:
  - information retrieval
tags:
  - IR
---

## 1. Brief
A summery of paper [*An analysis of Fusion Functions for Hybrid Retrieval*](https://arxiv.org/abs/2210.11934) and the following three articles.

[1]. [Introducing support for sparse-dense embeddings for better search results](https://www.pinecone.io/learn/sparse-dense/)

[2]. [Sparse-dense embeddings, keyword-aware semantic search, Concepts](https://docs.pinecone.io/docs/hybrid-search)

[3]. [Ecommerce Hybrid Search, Hybrid Search Case](https://docs.pinecone.io/docs/ecommerce-search)

## 2. Some useful information

**What does the paper contribute?**
The paper study hybrid search in text retrieval where lexical and semantic search are fused together with the
intuition that the two are complementary in how they model relevance.

convex combination(CC) of lexical and semantic scores, as well as the Reciprocal Rank Fusion(RRF) method

**What's retrieval?**
Retrieval is the first stage in a multi-stage ranking system, where the objetive is to find the top-k set of
documents, that are the most relevant to a given query q, from a large collection o f documents $D$. There're 2
major research questions: a)How do we measure the relevance between a query q and a document $d\in{D}$; and b) How
do we fine the top-k documents according to a given similarity metric efficiently.

**What is lexical search?**
Early methods model text as a Bag of Words(BoW) and compute the similarity of two pieces of text using a statistical
measure such as the term frequency-inverse document frequency(TF-IDF) family, with **BM25** being its most promient
member.

The paper refers to retrieval with a BoW model as *lexical search* and the similarity scores computed
by such a system as *lexical scores*, also known as key-word matching.

Actually in the artical [1], pinecone thinks new models like **SPLADE**, **uniCOIL** are better than **BM25**.
> Since then, progress continues to be made with alternative sparse models (e.g. SPLADE, uniCOIL),
> leading to even more relevant results than BM25.

Lexical search is simple, efficient, "zero-shot", and generally effective, but

    A. It's susceptible to the vocabulary mismatch problem and,

    B. It doesn't take into account the semantic similarity of queries and documents.


**What is semantic search?**
Semantics are what deep learning moduls are excellent at.
To learn a vector representation of quries and documents from pre-trained language models such as BERT does capture
their semantics, and thereby, reduc top-k retrieval to the problem of finding k nearest neighbors in the resulting
vector space.

The paper refers to this method as *semantic search* and the similarity scores computed by such a system as
*semantic scores*.

**What is hybrid search?**
For a query $q$ and ranked lists of documents $R_{LEX}$ and $R_{SEM}$ retrieved separatedly by lexical and semantic
search systems respectively, the task is to construct a final ranked list $R_{FUSION}$ so as to improve retrieval quality.
This is often referred to as hybrid search.

**Sparse vs. Dense**

Pinecone says in article [1] that vectors generated by BoW models are **sparse vector**, for they have large dimension(e.g. 100,000)
where only a small fraction of its entries are non-zero, used for texical search.

Vectors generated by ML models like SBERT are **dense vector**, they are vectors of fixed dimensions, typically between 100-1000,
where every entry is almost always non-zero. They may represent the learned semantic meaning of texts, used for semantic search.
